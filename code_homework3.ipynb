{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def hh_reflection(o_vec:np.ndarray, p_vec:np.ndarray) -> np.matrix:\n",
    "    v:np.ndarray\n",
    "    \"\"\"\n",
    "    Hausehold reflection operator\n",
    "    params:\n",
    "        o_vec: the original vector which want to be reflected\n",
    "        p_vec: the direction of reflected vector\n",
    "    return:\n",
    "        hh_ref: the reflection operator\n",
    "    \"\"\"\n",
    "    n = np.size(o_vec,)\n",
    "    v = o_vec - p_vec; v = v.reshape((n,1))\n",
    "    return np.eye(n) - 2 * (v @ v.T) / (v.T @ v)\n",
    "\n",
    "def eye_leftlow_cat(dim:int, mat:np.matrix) -> np.matrix:\n",
    "    \"\"\"\n",
    "    concat an eye matrix and a matrix on the diagnal \n",
    "    input:\n",
    "        mat: the matrix waiting to be concat\n",
    "    output:\n",
    "        mat: [[I,   0],\n",
    "              [0, mat]]\n",
    "    \"\"\"\n",
    "    if dim == 0: return mat # 若 dim = 0 返回原矩阵\n",
    "    mat_dim = mat.shape[0]; \n",
    "    mattop = np.c_[np.eye(dim), np.zeros((dim, mat_dim))] # 水平拼接\n",
    "    matbot = np.c_[np.zeros((mat_dim, dim)), mat]         # 水平拼接\n",
    "    return np.r_[mattop, matbot]                          # 垂直拼接\n",
    "\n",
    "def QR_factorization(mat:np.ndarray):\n",
    "    \"\"\"\n",
    "    QR-factorization of the input matrix using Hausehold Reflection method\n",
    "    input:\n",
    "        mat: the matrix to be QR factorized\n",
    "    output:\n",
    "        Q, R\n",
    "    \"\"\"\n",
    "    dim1 = mat.shape[1]; Q = np.eye(mat.shape[0]) # 初始化 Q 矩阵\n",
    "    for i in range(dim1): \n",
    "        if i == mat.shape[0] - 1: break # 如果是方阵, 最后一个元素不动\n",
    "        tmp_vec = mat[i:,i]; tmp_vec_norm = np.linalg.norm(tmp_vec, ord = 2) # 找到等待反射的向量\n",
    "        reflect_target = np.zeros_like(tmp_vec, dtype = np.float32); reflect_target[0] = tmp_vec_norm # 构造 [|a|,0,,...] 向量\n",
    "        reflect_operator = hh_reflection(tmp_vec, reflect_target) # 计算反射矩阵\n",
    "        reflect_operator = eye_leftlow_cat(dim = i, mat = reflect_operator) # 反射矩阵分块化\n",
    "        Q = Q @ reflect_operator # Q 矩阵累乘\n",
    "        mat = reflect_operator @ mat # 更新 R 矩阵\n",
    "    return Q, mat\n",
    "\n",
    "def QR_factorization_cpivot(mat:np.ndarray):\n",
    "    \"\"\"\n",
    "    QR-factorization of the input matrix using Hausehold Reflection method and column pivot\n",
    "    input:\n",
    "        mat: the matrix to be QR factorized\n",
    "    output:\n",
    "        Q, R, P.Transpose()\n",
    "        P is the permutation matrix which indicates: AP = QR\n",
    "    \"\"\"\n",
    "    def pair_pmat(n, ind1, ind2):\n",
    "        \"\"\"\n",
    "        Calculate the pair permutation matrix which switch the column ind1 and ind2\n",
    "        params:\n",
    "            n: the dimension of mat\n",
    "            ind1, ind2: the index to switch\n",
    "        return:\n",
    "            P: the permutation mat\n",
    "        \"\"\"\n",
    "        P = np.eye(n)\n",
    "        P[ind1, ind1] = 0; P[ind1, ind2] = 1\n",
    "        P[ind2, ind2] = 0; P[ind2, ind1] = 1\n",
    "        return P\n",
    "\n",
    "    dim1 = mat.shape[1]; Q, P = np.eye(mat.shape[0]), np.eye(mat.shape[1]) # 初始化 Q, P 矩阵\n",
    "    for i in range(dim1): \n",
    "        if i == mat.shape[0] - 1: break # 如果是方阵, 最后一个元素不动\n",
    "        pivot_ind = np.argmax(np.abs(mat[i,:])) # 主元位置\n",
    "        pivot = mat[i, pivot_ind]; P_tmp = pair_pmat(dim1, i, pivot_ind)\n",
    "        mat = mat @ P_tmp\n",
    "        tmp_vec = mat[i:,i]; tmp_vec_norm = np.linalg.norm(tmp_vec, ord = 2) # 找到等待反射的向量\n",
    "        reflect_target = np.zeros_like(tmp_vec, dtype = np.float32); reflect_target[0] = tmp_vec_norm # 构造 [|a|,0,,...] 向量\n",
    "        reflect_operator = hh_reflection(tmp_vec, reflect_target) # 计算反射矩阵\n",
    "        reflect_operator = eye_leftlow_cat(dim = i, mat = reflect_operator) # 反射矩阵分块化\n",
    "        Q = Q @ reflect_operator # Q 矩阵累乘\n",
    "        mat = reflect_operator @ mat # 更新 R 矩阵\n",
    "        P = P @ P_tmp # 更新 P 矩阵\n",
    "    return Q, mat, P.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.02257621,  0.53672414, -0.8434557 ],\n",
       "        [ 0.11288091,  0.83690717,  0.53557846],\n",
       "        [ 0.99335201, -0.10730138, -0.04169172]]),\n",
       " array([[ 4.42944692e+01,  9.82063930e+00,  1.17170386e+01],\n",
       "        [-6.88968549e-07,  7.03953434e+00,  6.52474855e+00],\n",
       "        [ 1.08270600e-06,  9.92445787e-07, -1.46241660e+00]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QR_factorization(np.array([[1,4,5],[5,7,6],[44,9,11]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.33104236, -0.42307606,  0.84345575],\n",
       "        [ 0.57932412, -0.61444232, -0.53557837],\n",
       "        [ 0.7448453 ,  0.66593339,  0.04169173]]),\n",
       " array([[ 1.20830460e+01,  3.60008561e+01],\n",
       "        [ 8.93127502e-09,  2.58057815e+01],\n",
       "        [-1.78056284e-08,  8.29364610e-08]]),\n",
       " array([[0., 1.],\n",
       "        [1., 0.]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QR_factorization_cpivot(np.array([[1,4],[5,7],[44,9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 12)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.linalg  import cholesky\n",
    "from numpy.polynomial.polynomial import polyval\n",
    "\n",
    "m = 21; n = 12; eps = 1e-10; c0 = np.ones(n)\n",
    "t = np.linspace(0, 1, m); y0 = polyval(x = t, c = c0)\n",
    "y0 = y0 + (np.random.uniform(low = 0, high = 1, size = y0.shape) * 2 - 1) * eps\n",
    "\n",
    "\n",
    "# Van der Monde 矩阵\n",
    "Vo = np.vander(t, N = n, increasing=True)\n",
    "Vo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14059603340600213"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 法线方程部分\n",
    "L = cholesky(Vo.T @ Vo) # cholesky factorization\n",
    "b = Vo.T @ y0           # 法线方程右端\n",
    "tmp_c = np.linalg.solve(L, b); c_normal = np.linalg.solve(L.T, tmp_c)\n",
    "error_normal = np.linalg.norm(c_normal - c0)\n",
    "error_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000630076542429547"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# QR 分解部分\n",
    "Q, R = QR_factorization(Vo) # QR factorization without column pivot\n",
    "R = R[:R.shape[1],:]        # 丢掉 0 行\n",
    "b = (Q.T @ y0)[:R.shape[1]] # 等式右侧也同样去掉相同的行\n",
    "c_qr = np.linalg.solve(R, b)\n",
    "error_qr = np.linalg.norm(c_qr - c0)\n",
    "error_qr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006198408113126203"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cpivot-QR 分解部分\n",
    "Q, R, P = QR_factorization_cpivot(Vo) # QR factorization with column pivot\n",
    "R = R[:R.shape[1],:]        # 丢掉 0 行\n",
    "b = (Q.T @ y0)[:R.shape[1]] # 等式右侧也同样去掉相同的行\n",
    "c_qr = np.linalg.solve(R, b)\n",
    "c_qr_cpivot = P.T @ c_qr\n",
    "error_qr_pivot = np.linalg.norm(c_qr_cpivot - c0)\n",
    "error_qr_pivot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f31b5846fe4d0e510ff280a80fa1fd1567c5c662c3b99a86eb737e0309da4a2e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
